{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4PSXC6zVQws6HqdFFgQfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starirene9/DeepLearningAssignment/blob/main/GradioAnnotatedImage_K2024504%EA%B5%AC%EB%B9%9B%EB%82%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyx6cZmH2bMR",
        "outputId": "5a102863-21be-4587-86fe-b4a0062b6ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apixxZi33c7p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "b03528fc-2979-48d5-ed50-b7120182bba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6a42e504081d8faaf7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6a42e504081d8faaf7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def generate_detection(image):\n",
        "  annotations= [] # 감지된 객체 정보를 저장할 리스트\n",
        "  label = [\"cat\", \"dog\", \"bird\"]\n",
        "  for _ in range(random.randint(1,3)): # 객체 수를 1~3개 사이에서 랜덤으로 결정\n",
        "    x = random.randint(0, image.shape[1]) # 랜덤 x 좌표 (가로 시작점)\n",
        "    y = random.randint(0, image.shape[0]) # 랜덤 y 좌표 (세로 시작점)\n",
        "    w = random.randint(10, 100) # 박스의 가로 너비\n",
        "    h = random.randint(10, 100) # 박스의 세로 높이\n",
        "    box = (x, y, x + w, y + h) # 박스를 나타내는 좌표 튜플 (x1, y1, x2, y2)\n",
        "    label = random.choice(label) # 라벨 중 하나를 랜덤으로 선택\n",
        "    annotations.append((box, label)) # 박스와 라벨을 튜플로 묶어 리스트에 추가\n",
        "  return (image, annotations)  # 원본 이미지와 감지된 객체 리스트 반환\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"## Object Detection Demo\")\n",
        "  with gr.Row():\n",
        "    img_input = gr.Image(label=\"Input Image\")\n",
        "    annotated_output = gr.AnnotatedImage(\n",
        "        label = \"Detected Objects\",\n",
        "        color_map = {\"cat\":\"#ff0000\", \"dog\": \"#00ff00\", \"bird\": \"#0000ff\"}\n",
        "    )\n",
        "  with gr.Row():\n",
        "    detect_button = gr.Button(\"Detect Objects\")\n",
        "\n",
        "  detect_button.click(generate_detection, inputs=img_input, outputs=annotated_output)\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image segmentation with mask : hypotheticall one\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_segmentation(image):\n",
        "  annotations = []\n",
        "  labels = [\"sky\", \"grass\", \"building\"]\n",
        "  for _ in range(random.randint(1,3)):\n",
        "    x = random.randint(0, image.shape[1])\n",
        "    y = random.randint(0, image.shape[0])\n",
        "    r = random.randint(20, 50) #마스크의 반지름도 랜덤 (즉, 원형 영역의 크기)\n",
        "    mask = np.zeros(image.shape[:2]) #이미지와 같은 **높이(height), 너비(width)**를 가진 2D 배열을 만듦\n",
        "    for i in range(image.shape[0]): # 이미지의 세로(높이)에 해당하는 모든 y좌표 순회\n",
        "      for j in range(image.shape[1]): # 이미지의 가로(너비)에 해당하는 모든 x좌표 순회\n",
        "        if (i - y)**2 + (j -x)**2 < r**2: #현재 픽셀 (j, i)가 원 중심에서 얼마나 떨어져 있는지를 나타냄 그 거리가 반지름 r보다 작으면 → 픽셀이 원 안에 있다는 뜻\n",
        "          mask[i,j] = 1 #이미지의 각 픽셀을 순회하면서 (i, j) 좌표가 원 안에 들어오면 1로 표시 (마스크 내부)\n",
        "    annotations.append((mask, random.choice(labels)))\n",
        "    \"\"\"\n",
        "    image[i][j]  →  i: 세로(행, y), j: 가로(열, x)\n",
        "    i는 y 방향 (위에서 아래로 내려감), j는 x 방향 (왼쪽에서 오른쪽으로 감)\n",
        "\n",
        "    image.shape = (height, width, channels)\n",
        "    이미지는 2D 배열이고, 배열은 [y][x] = [행][열] = [i][j] 순으로 접근\n",
        "\n",
        "    만든 마스크와 랜덤으로 선택된 라벨을 튜플 형태로 리스트에 추가\n",
        "\t  최종적으로 [(mask1, label1), (mask2, label2), ...] 같은 구조가 만들어지며\n",
        "\t  이 구조는 Gradio의 gr.AnnotatedImage 컴포넌트에서 사용할 수 있는 형식\n",
        "    \"\"\"\n",
        "  return (image, annotations)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"## Image Segmentation Demo\")\n",
        "  with gr.Row():\n",
        "    img_input = gr.Image(label=\"Input Image\")\n",
        "    seg_output = gr.AnnotatedImage(\n",
        "        label = \"Segments\",\n",
        "        color_map = {\"sky\":\"#ff0000\", \"grass\": \"#00ff00\", \"building\": \"#0000ff\"}\n",
        "    )\n",
        "  with gr.Row():\n",
        "    segment_button = gr.Button(\"Segment Image\")\n",
        "\n",
        "  segment_button.click(generate_segmentation, inputs=img_input, outputs=seg_output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "1hAQ-OR52F6y",
        "outputId": "5e655d44-163e-4156-85b1-2c33c16d28f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4b850a71ac4fe31b44.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4b850a71ac4fe31b44.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_annotation(img):\n",
        "    annotations = []\n",
        "    for _ in range(3):\n",
        "        x, y, w, h = np.random.randint(0, img.shape[1], size=4)\n",
        "        label = random.choice([\"Labrador\", \"Car\", \"Bird\"])\n",
        "        annotations.append(((x, y, x + w, y + h), label))\n",
        "    return (img, annotations)\n",
        "\n",
        "\"\"\"\n",
        "np.random.randint(0, img.shape[1], size=4)\n",
        "\n",
        "0 이상 img.shape[1] 미만의 정수를\n",
        "4개 생성하여\n",
        "(x, y, w, h)로 사용하려는 코드\n",
        "\n",
        "annotations.append(((x, y, x + w, y + h), label))\n",
        "\n",
        "[\n",
        "  ((100, 50, 180, 130), \"Bird\"),\n",
        "  ((20, 70, 90, 150), \"Car\"),\n",
        "  ((200, 100, 260, 160), \"Labrador\")\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Custom Colors\")\n",
        "    with gr.Row():\n",
        "        img_input = gr.Image(label=\"Input Image\")\n",
        "        ann_output = gr.AnnotatedImage(\n",
        "            color_map={\n",
        "                \"Labrador\": \"#ff0000\",\n",
        "                \"Car\": \"#00ff00\",\n",
        "                \"Bird\": \"#0000ff\"\n",
        "            }\n",
        "        )\n",
        "        add_annotations_btn = gr.Button(\"Add Colorful Annotations\")\n",
        "\n",
        "        add_annotations_btn.click(generate_annotation, inputs=img_input, outputs=ann_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "f0wKATJx2Fw6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "9adab155-6ebb-4081-d71c-b9c628fad629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4d330a44f8b42fcd1e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4d330a44f8b42fcd1e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 gr.AnnotatedImage:\n",
        "\n",
        "주석(annotation)이 포함된 이미지 컴포넌트\n",
        "\t•\t이미지 위에 사각형, 라벨 같은 주석(annotation)을 시각적으로 표시할 수 있어요.\n",
        "\t•\t(x1, y1, x2, y2), label 형식의 주석 리스트를 이미지 위에 겹쳐서 보여줍니다.\n",
        "\t•\tcolor_map 옵션을 통해 라벨별 색상도 설정 가능해요.\n",
        "  \n",
        "주요 용도:\n",
        "\t•\t객체 감지 결과를 시각적으로 보여줄 때 (예: Tumor, Car, Person 등)\n",
        "\t•\t이미지 분석 결과에 시각적인 마킹을 추가할 때"
      ],
      "metadata": {
        "id": "jodO1if81XsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def annotate_medical_image(image: np.ndarray) -> tuple[np.ndarray, list[tuple[int,int,int,int]]]:\n",
        "  height, width = image.shape[:2]\n",
        "  annotations = []\n",
        "\n",
        "  \"\"\"\n",
        "image: np.ndarray : 함수의 매개변수 image는 NumPy 배열 형식의 이미지라는 뜻입니다.\n",
        "\t->\n",
        "tuple[np.ndarray, list[tuple[int, int, int, int]]]\n",
        "이 함수는 튜플을 반환하는데:\n",
        "\t1.\t첫 번째는 np.ndarray: 원본 이미지\n",
        "\t2.\t두 번째는 [(x1, y1, x2, y2), label] 형태의 주석 리스트\n",
        "\n",
        "“입력받은 의료 이미지를 분석해서, 이미지 위에 ‘Tumor’ 라는 주석을 여러 개 붙여주는 함수”\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  #simulate tumor detection\n",
        "  num_tumors = random.randint(1,3)\n",
        "  for i in range(num_tumors):\n",
        "    x1 = random.randint(0, width - 100)\n",
        "    y1 = random.randint(0, height - 100)\n",
        "    x2 = x1 + random.randint(50, 150)\n",
        "    y2 = y1 + random.randint(50, 150)\n",
        "    annotations.append(((x1, y1, x2, y2), \"Tumor\"))\n",
        "  return (image, annotations)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Row():\n",
        "    image_input = gr.Image(label=\"Upload Medical Image\")\n",
        "    annotated_output = gr.AnnotatedImage(\n",
        "        label = \"Medical Annotations\",\n",
        "        color_map = {\"Tumor\": \"#ff0000\"}\n",
        "    )\n",
        "  annotated_button = gr.Button(\"Annotated Image\")\n",
        "  annotated_button.click(annotate_medical_image, inputs=image_input, outputs=annotated_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "jflupInwyKA8",
        "outputId": "b776def8-0ae3-4c29-d040-aeb1978ad94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7f75153f156c7b760f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7f75153f156c7b760f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d6ulL7B22qf",
        "outputId": "c3c4ac4f-1ff9-4416-ab73-25f9fefd762d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.4.3 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "\n",
        "def detect_faces(image):\n",
        "  detector = MTCNN()\n",
        "  faces = detector.detect_faces(image) #감지된 얼굴 각각을 딕셔너리로 담은 리스트를 반환\n",
        "  annotations = []\n",
        "  #labels = [\"Face\"] * len(faces) #\"Face\"라는 라벨을 faces의 길이만큼 복제한 리스트를 만들어주는 간단한 파이썬 문법 <- 코드는 영상에서 작성되었지만 쓰이지 않음\n",
        "  for face in faces :\n",
        "    x, y, w, h = face[\"box\"]\n",
        "    annotations.append(((x, y, x + w, y + h), \"Face\"))\n",
        "  return (image, annotations)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"## Face Detection Demo\")\n",
        "  with gr.Row():\n",
        "    img_input = gr.Image(label=\"Upload Image\")\n",
        "    face_output = gr.AnnotatedImage(\n",
        "        label = \"Detected Faces\",\n",
        "        color_map = {\"Face\": \"#ffd700\"}\n",
        "    )\n",
        "  with gr.Row():\n",
        "    detect_button = gr.Button(\"Detect Faces\")\n",
        "  detect_button.click(detect_faces, inputs=img_input, outputs=face_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "1u3kkzTfzCBm",
        "outputId": "87f0e80c-e31d-489c-a321-3e31824a9626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8821ea80ed0ba0fc9d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8821ea80ed0ba0fc9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}